{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate functional brain connectivity and certain graph theory metrics (currently limited to weighted degree centrality):\n",
    "\n",
    "### Check https://pubmed.ncbi.nlm.nih.gov/24238796/ , https://www.sciencedirect.com/science/article/pii/S0924977X10000684 , https://pubmed.ncbi.nlm.nih.gov/20817103/ and https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7086233/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import graph_tool.all as gt\n",
    "\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_load(folder, img):\n",
    "    \"\"\"Load an image from a single brain.\n",
    "    \n",
    "    The function returns a brain image as a nibabel image object.\n",
    "    \n",
    "    Args:\n",
    "        folder (string): Image directory.\n",
    "        img (string): Image filename.\n",
    "        \n",
    "    Returns:\n",
    "        fmri_image (nibabel.nifti1.Nifti1Image:): Brain image.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    img_path = os.path.join(folder, img)\n",
    "    fmri_image = nib.load(img_path)\n",
    "    #print(fmri_image.shape)\n",
    "    return fmri_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a resampled, binarised GM mask\n",
    "def mask_img_load(folder, img):\n",
    "    \"\"\"Load a brain mask image.\n",
    "    \n",
    "    The function returns a brain mask image as a nibabel image object.\n",
    "    \n",
    "    Args:\n",
    "        folder (string): Mask image directory.\n",
    "        img (string): Mask image filename.\n",
    "        \n",
    "    Returns:\n",
    "        mask (nibabel.nifti1.Nifti1Image:): Mask image.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    img_path = os.path.join(folder, img)\n",
    "    mask = nib.load(img_path)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_series(fmri_image, mask):\n",
    "    \"\"\"Extract the timeseries from a single brain (fMRI image).\n",
    "    \n",
    "    The function returns the timeseries data from each brain voxel.\n",
    "    \n",
    "    Args:\n",
    "        fmri_image (string): Brain image (fMRI).\n",
    "        mask (string): Mask image.\n",
    "        \n",
    "    Returns:\n",
    "        brain_time_series (ndarray): A timeseries array in the format [n_volumes, n_voxels].\n",
    "        brain_masker (NiftiMasker): A NiftiMasker object that could be used to extract timeseries from fMRI images or transform 2D timeseries arrays back into 4D fMRI images.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    brain_masker = NiftiMasker(mask, memory='nilearn_cache', memory_level=1, verbose=0)\n",
    "    brain_time_series = brain_masker.fit_transform(fmri_image)\n",
    "    return brain_time_series, brain_masker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity is equal to Pearson R when data is centered:\n",
    "### Check https://stats.stackexchange.com/questions/235673/is-there-any-relationship-among-cosine-similarity-pearson-correlation-and-z-sc and https://matthew-brett.github.io/teaching/correlation_projection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim_func(time_series):\n",
    "    \"\"\"Compute cosine similarity on each pair of voxel timeseries.\n",
    "    \n",
    "    The function returns a voxel-wise functional connectivity matrix as calculated by cosine similarity.\n",
    "    \n",
    "    Args:\n",
    "        time_series (ndarray): A brain timeseries array in the format [n_volumes, n_voxels].\n",
    "        \n",
    "    Returns:\n",
    "        cos_sim (ndarray): A connectivity (i.e. adjacency) matrix of the brain voxels in the format [n_voxels, n_voxels].\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    cos_sim = cosine_similarity(time_series.T, time_series.T)\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold the adjacency matrix\n",
    "def thresh_mat(adjacency_matrix):\n",
    "    \"\"\"Threshold the adjacency matrix.\n",
    "    \n",
    "    The function returns a thresholded adjacency matrix with diagonal values set to 0.\n",
    "    \n",
    "    Args:\n",
    "        adjacency_matrix (ndarray): An adjacency matrix in the format [n_voxels, n_voxels].\n",
    "        \n",
    "    Returns:\n",
    "        adjacency_matrix (ndarray): A thresholded adjacency matrix in the format [n_voxels, n_voxels].\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # threshold at r > 0.25\n",
    "    adjacency_matrix[adjacency_matrix < 0.25] = 0\n",
    "    # fill diagonal with zeroes\n",
    "    np.fill_diagonal(adjacency_matrix, 0)\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using graph-tool (https://graph-tool.skewed.de/)\n",
    "### check https://carlonicolini.github.io/sections/science/2018/09/12/weighted-graph-from-adjacency-matrix-in-graph-tool.html for the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_graph_tool(adj):\n",
    "     \"\"\"Create an undirected, weighted graph with graph-tool from the adjacency matrix.\n",
    "    \n",
    "    The function returns an undirected, weighted graph derived from the adjacency matrix.\n",
    "    \n",
    "    Args:\n",
    "        adj (ndarray): An adjacency matrix in the format [n_voxels, n_voxels].\n",
    "        \n",
    "    Returns:\n",
    "        g (graph_tool.Graph): A graph object.\n",
    "        \n",
    "    \"\"\"\n",
    "        \n",
    "    g = gt.Graph(directed=False)\n",
    "    edge_weights = g.new_edge_property('double')\n",
    "    g.edge_properties['weight'] = edge_weights\n",
    "    # Set the lower triangle of the adjacency matrix and the diagonal to 0\n",
    "    nnz = np.nonzero(np.triu(adj,1))\n",
    "    # Get the number of edges (i.e. non-zero values)\n",
    "    nedges = len(nnz[0])\n",
    "    # Create the edge value list\n",
    "    g.add_edge_list(\n",
    "        # Create rows of THREE values\n",
    "        np.hstack(\n",
    "        [\n",
    "        # Transpose nnz so that you have TWO values in each row, where\n",
    "        # the first is the row index and the second is the column index\n",
    "        # of this particular edge\n",
    "        np.transpose(nnz),\n",
    "        # Get the 3RD values for each row, i.e. the edge weight\n",
    "        np.reshape(adj[nnz],(nedges,1))\n",
    "        ]\n",
    "        ),\n",
    "    # If given, eprops should specify an iterable containing edge property maps that will be filled with the remaining values at each row, if there are more than two.\n",
    "    eprops=[edge_weights])\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dc(adjacency_matrix):\n",
    "    \"\"\"Get n of degrees for each voxel (first option) or get the weighted sum for each voxel (second option).\n",
    "    \n",
    "    The function returns a degree centrality array derived from the graph.\n",
    "    \n",
    "    Args:\n",
    "        adjacency_matrix (ndarray): An adjacency matrix in the format [n_voxels, n_voxels].\n",
    "        \n",
    "    Returns:\n",
    "        dc (ndarray): A 1D voxel-wise degree centrality array.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    g = to_graph_tool(adjacency_matrix)\n",
    "    \n",
    "    #Un-weighted\n",
    "    #dc = g.get_total_degrees([i for i in range(adjacency_matrix.shape[0])])\n",
    "    \n",
    "    #Weighted\n",
    "    weights = g.degree_property_map(\"total\", g.edge_properties['weight'])\n",
    "    dc_list = [weights[i] for i in range(adjacency_matrix.shape[0])]\n",
    "    dc = np.array(dc_list)\n",
    "    \n",
    "    return dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score\n",
    "#def z_score_dc(dc_array):\n",
    "#    dc = dc_array.reshape(-1, 1)\n",
    "#    scaler = StandardScaler()\n",
    "#    dc_scaled = scaler.fit_transform(dc)\n",
    "#    return dc_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_nifti(brain_masker,dc_array):\n",
    "    \"\"\" Transform the degree centrality array into a NIfTI volume and save.\n",
    "\n",
    "    The function returns a degree centrality image.\n",
    "    \n",
    "    Args:\n",
    "        brain_masker (NiftiMasker): A NiftiMasker object that could be used to extract timeseries from fMRI images or transform 2D timeseries arrays back into 4D fMRI images.\n",
    "        dc_array (ndarray): A 1D voxel-wise degree centrality array.\n",
    "        \n",
    "    Returns:\n",
    "        dc_img (nibabel.nifti1.Nifti1Image:): Degree centrality image.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    dc_img = brain_masker.inverse_transform(dc_array.T)\n",
    "    return dc_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the DC analysis on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dc_auto(fMRIroot, fMRI_txt, MASKroot, GM_mask):\n",
    "    \"\"\" Calculate functional connectivity and degree centrality from an adjacency matrix and save the DC images to disk.\n",
    "    \n",
    "    Args:\n",
    "        fMRIroot (string): fMRI image directory.\n",
    "        fMRI_txt (string): A txt file containing the fMRI image filenames.\n",
    "        MASKroot (string): Mask image directory.\n",
    "        GM_mask (string): Mask image filename.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # transform the txt file into a Python list... of lists!\n",
    "    fmri_list = []\n",
    "    with open(fMRI_txt, newline='') as inputfile:\n",
    "        for row in csv.reader(inputfile):\n",
    "            fmri_list.append(row)\n",
    "    \n",
    "    for i in range(len(fmri_list)):\n",
    "        # load an image from a single brain:\n",
    "        fmri_image = img_load(fMRIroot, fmri_list[i][0])\n",
    "        print(\"Participant \" + fmri_list[i][0])\n",
    "        print(\"The image dimensions are: \" + str(fmri_image.shape))\n",
    "        \n",
    "        # load the GM mask\n",
    "        gm_mask = mask_img_load(MASKroot, GM_mask)\n",
    "        print(\"GM mask loaded.\")\n",
    "        \n",
    "        # create a NiftiMasker object and extract the time series\n",
    "        brain_time_series, brain_masker = extract_time_series(fmri_image, gm_mask)\n",
    "        print(\"Time series extracted.\")\n",
    "        \n",
    "        # calculate the correlations between each pair of voxels\n",
    "        cos_sim = cos_sim_func(brain_time_series)\n",
    "        print(\"Correlations calculated.\")\n",
    "        \n",
    "        # threshold the matrix\n",
    "        adjacency_matrix = thresh_mat(cos_sim)\n",
    "        print(\"Adjacency matrix thresholded.\")\n",
    "        \n",
    "        # calculate the degree centrality (DC)\n",
    "        dc = calc_dc(adjacency_matrix)\n",
    "        print(\"Raw wDC values calcualted.\")\n",
    "        \n",
    "        # convert the raw DC matrix and save it as a NIfTI image\n",
    "        dc_img = array_to_nifti(brain_masker,dc)\n",
    "        dc_img_name = fmri_list[i][0][:6] + \"_wDC_raw\"\n",
    "        nib.save(dc_img, dc_img_name)\n",
    "        print(\"Raw wDC image of the whole GM of \" + fmri_list[i][0][:6] + \" saved.\")\n",
    "        \n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the analysis\n",
    "calc_dc_auto(\"/Volumes/Seagate Dr/PhD/CBD/BOLD_data\",\n",
    "             \"/Users/mishodimitrov/Downloads/PhD/Analysis/CBD/Data/cbd_session_list.txt\",\n",
    "             \"/Users/mishodimitrov/Downloads/PhD/Analysis/CBD/Data/Masks/GM\",\n",
    "            \"final_resampled_GM_mask_3.0mmMNI.nii.gz\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
